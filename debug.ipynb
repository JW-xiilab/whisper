{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed to kjw_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.87G/2.87G [02:31<00:00, 20.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: torch.Size([1, 3])\n",
      "audio_features: torch.Size([1, 1500, 1280])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m AUDIO \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnews_mbc_busan.mp3\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mlarge-v2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe_kjw(AUDIO)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/transcribe_kjw.py:236\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    233\u001b[0m mel_segment \u001b[39m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(dtype)\n\u001b[1;32m    235\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 236\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[1;32m    237\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/transcribe_kjw.py:164\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    161\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m options \u001b[39m=\u001b[39m DecodingOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, temperature\u001b[39m=\u001b[39mt)\n\u001b[0;32m--> 164\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(segment, options)\n\u001b[1;32m    166\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    168\u001b[0m     compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    170\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/decoding.py:840\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    838\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 840\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39;49mrun(mel)\n\u001b[1;32m    842\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/decoding.py:753\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    750\u001b[0m tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mrepeat_interleave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(audio_features\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    752\u001b[0m \u001b[39m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_loop(audio_features, tokens)\n\u001b[1;32m    755\u001b[0m \u001b[39m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    756\u001b[0m audio_features \u001b[39m=\u001b[39m audio_features[:: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group]\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/decoding.py:703\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_len):\n\u001b[0;32m--> 703\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference\u001b[39m.\u001b[39;49mlogits(tokens, audio_features)\n\u001b[1;32m    705\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    706\u001b[0m             i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mno_speech \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m         ):  \u001b[39m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    708\u001b[0m             probs_at_sot \u001b[39m=\u001b[39m logits[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msot_index]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/DATA_17/kjw/01-FeatureExtraction/whisper/whisper/decoding.py:164\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtokens: \u001b[39m\u001b[39m{\u001b[39;00mtokens\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maudio_features: \u001b[39m\u001b[39m{\u001b[39;00maudio_features\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkv_cache: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkv_cache\u001b[39m.\u001b[39;49mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------------>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m offset \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkv_cache\u001b[39m.\u001b[39mvalues()))\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkv_cache \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# AUDIO = 'harvard.wav'\n",
    "AUDIO = 'news_mbc_busan.mp3'\n",
    "model = whisper.load_model(\"large-v2\")\n",
    "result = model.transcribe_kjw(AUDIO)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'segments', 'language'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' 최근',\n",
       "  ' 6년간',\n",
       "  ' 부산에서는',\n",
       "  ' 초중고',\n",
       "  ' 교사',\n",
       "  ' 9명이',\n",
       "  ' 우울증이나',\n",
       "  ' 공황장애',\n",
       "  ' 등을',\n",
       "  ' 호소하며'],\n",
       " [' 스스로', ' 생을', ' 마감했습니다', '.', ' 3년간', ' 열린', ' 교권보호위원회도', ' 240건에'],\n",
       " [' 달하는데요', '.', ' 교사들은', ' 재발을', ' 막기', ' 위해', ' 문제', ' 학생들의'],\n",
       " [' 치료와', ' 같은', ' 구체적인', ' 대책을', ' 요구하고', ' 있습니다', '.'],\n",
       " [' 김윤아', ' 기자의', ' 보도입니다', '.'],\n",
       " [' ', '-!(기자', ',', ' 영상편집)]', ' 부산', ' 북구의', ' 한', ' 중학교', '.'],\n",
       " [' 지난',\n",
       "  ' 6월',\n",
       "  ' 2학년',\n",
       "  ' 남학생이',\n",
       "  ' 교무실에서',\n",
       "  ' 40대',\n",
       "  ' 남성',\n",
       "  ' 교사에게',\n",
       "  ' 주먹을',\n",
       "  ' 휘둘렀습니다',\n",
       "  '.'],\n",
       " [' 피해', ' 교사는', ' 얼굴과', ' 가슴을', ' 맞아', ' 현재', ' 병가', ' 중입니다', '.'],\n",
       " [' 이', ' 학생은', ' 1학기', ' 내내', ' 교사들에게', ' 욕설을', ' 했다고', ' 합니다', '.'],\n",
       " [' 이', ' 사건은', ' 경찰의', ' 고소장이', ' 접수돼', ' 현재', ' 수사가', ' 진행', ' 중입니다', '.'],\n",
       " [' 학교', ' 측은', ' 교권보호위원회를', ' 열고', ' 해당'],\n",
       " [' 학생에게', ' 최고', ' 수위', ' 징계인', ' 강제', ' 전학', ' 조치를', ' 내렸습니다', '.'],\n",
       " [' 기장군의',\n",
       "  ' 한',\n",
       "  ' 중학교에서도',\n",
       "  ' 최근',\n",
       "  ' 기간제',\n",
       "  ' 교사가',\n",
       "  ' 담임을',\n",
       "  ' 그만두고',\n",
       "  ' 병가를',\n",
       "  ' 낸',\n",
       "  ' 일도'],\n",
       " [' 있었습니다', '.', ' 반말하고', ' 등교도', ' 하지', ' 않는', ' 학생을'],\n",
       " [' 교사가', ' 제지하자', ' 학부모가', ' 석', ' 달간', ' 문자'],\n",
       " [' 메시지로', ' 해당', ' 교사를', ' 괴롭혀온', ' 것입니다', '.'],\n",
       " [' ', '-', '-', '.'],\n",
       " [' ', '-', '-', '.', ' 지난', ' 6년', ' 동안', ' 부산에서는', ' 초중고'],\n",
       " [' 교사',\n",
       "  ' 9명이',\n",
       "  ' 우울증이나',\n",
       "  ' 공황장애',\n",
       "  ' 등을',\n",
       "  ' 이유로',\n",
       "  ' 극단적',\n",
       "  ' 선택을',\n",
       "  ' 했습니다',\n",
       "  '.'],\n",
       " [' 지난', ' 3년', ' 동안', ' 부산에서', ' 확인된', ' 교권'],\n",
       " [' 침해', ' 사례는', ' 모두', ' 249건에', ' 달합니다', '.'],\n",
       " [' 교사들은',\n",
       "  ' 대다수',\n",
       "  ' 문제',\n",
       "  ' 학생들이',\n",
       "  ' 우울증이나',\n",
       "  ' 성격',\n",
       "  ' 장애를',\n",
       "  ' 앓는',\n",
       "  ' 경우가',\n",
       "  ' 많다며'],\n",
       " [' 학교에', ' 모든', ' 것을', ' 맡길', ' 게', ' 아니라', ' 문제'],\n",
       " [' 학생들에', ' 대한', ' 치료', ' 대책이', ' 필요하다고', ' 증언했습니다', '.'],\n",
       " [' ', '-', '-', '.', ' 앞서', ' 북구', ' 한', ' 초등학교에서', ' 학생이'],\n",
       " [' 교사를', ' 폭행해', ' 전치', ' 3주', ' 골절상을', ' 입힌'],\n",
       " [' 사건과', ' 관련해', ' 부산교육청은', ' 오는', ' 7일'],\n",
       " [' 교육청', ' 집권으로', ' 교권보호위원회를', ' 열', ' 방침입니다', '.'],\n",
       " [' MBC', ' 뉴스', ' 김민아입니다', '.'],\n",
       " [' ', '-', '-', '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[seg['token_words'] for seg in result['segments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "AUDIO = 'harvard.wav'\n",
    "model = whisper.load_model(\"large-v2\")\n",
    "result = model.transcribe(AUDIO)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(AUDIO)\n",
    "audio = whisper.pad_or_trim(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n"
     ]
    }
   ],
   "source": [
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.\n"
     ]
    }
   ],
   "source": [
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mel\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mel' is not defined"
     ]
    }
   ],
   "source": [
    "mel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
